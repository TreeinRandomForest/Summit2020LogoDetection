{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import detectron2\n",
    "import cv2\n",
    "import os\n",
    "import pathlib\n",
    "import json\n",
    "import random\n",
    "from PIL import Image, ImageDraw2\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.structures import BoxMode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "\n",
    "* dataset generation with one logo\n",
    "    *  logo -> transform -> overlay on background. bbox known (img dimensions)\n",
    "    \n",
    "    * logo with bbox -> transform img and bbox (imgaug)\n",
    "\n",
    "* exporting to onnx and make it work with existing code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generation\n",
    "\n",
    "* Offline\n",
    "\n",
    "    * Generate N arbitrary colored backgrounds (DONE)\n",
    "\n",
    "    * Transform transparent logo (DONE)\n",
    "    \n",
    "    * Overlay transformed and transparent logo onto background (DONE)\n",
    "    \n",
    "    * Save image and bounding box (DONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_background_image(color_center, color_edge, size=(512,512)):\n",
    "    #distance calculation\n",
    "    row_idx = np.repeat(np.arange(0, size[0]), size[1], axis=0).reshape(size)\n",
    "    col_idx = np.repeat(np.arange(0, size[1]), size[0], axis=0).reshape((size[1], size[0])).T    \n",
    "    \n",
    "    center = (size[0]/2, size[1]/2)\n",
    "    dist = np.zeros(size)\n",
    "    dist = np.sqrt((row_idx - center[0])**2 + (col_idx - center[1])**2)\n",
    "    max_dist = np.max(dist)\n",
    "    dist /= max_dist    \n",
    "    \n",
    "    #colors\n",
    "    r = color_edge[0] * dist + color_center[0] * (1-dist)\n",
    "    g = color_edge[1] * dist + color_center[1] * (1-dist)\n",
    "    b = color_edge[2] * dist + color_center[2] * (1-dist)    \n",
    "    \n",
    "    #check artifacts with Image.fromarray()\n",
    "    img = Image.new('RGBA', size)\n",
    "    for y in range(size[1]):\n",
    "        for x in range(size[0]):\n",
    "            img.putpixel((x,y), (int(r[x,y]), int(g[x,y]), int(b[x,y])))\n",
    "    \n",
    "    return img\n",
    "\n",
    "def retrieve_background_image(LOC):\n",
    "    raise NotImplementedError\n",
    "\n",
    "def make_logo_transparent(logo, threshold_color=[200,200,200]):\n",
    "    logo = logo.convert('RGBA')\n",
    "    data = logo.getdata()\n",
    "    \n",
    "    data_alpha = []\n",
    "    for pixel in data:\n",
    "        #if pixel[0]>200 and pixel[1]>200 and pixel[2]>200:\n",
    "        if pixel[0]>threshold_color[0] and pixel[1] > threshold_color[1] and pixel[2] > threshold_color[2]:\n",
    "            data_alpha.append((pixel[0], pixel[1], pixel[2], 0))\n",
    "            #data_alpha.append((0,255,0,0))\n",
    "        else:\n",
    "            data_alpha.append((pixel[0], pixel[1], pixel[2], pixel[3]))\n",
    "        \n",
    "    logo.putdata(data_alpha)\n",
    "    \n",
    "    return logo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logo = Image.open('RHLOGO.jpg')\n",
    "logo = make_logo_transparent(logo)\n",
    "logo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logo = Image.open('ANACONDALOGO.jpg')\n",
    "logo = make_logo_transparent(logo)\n",
    "logo = logo.resize((128,128))\n",
    "logo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logo = Image.open('CLOUDERALOGO.jpg')\n",
    "logo = make_logo_transparent(logo)\n",
    "logo = logo.resize((128,128))\n",
    "logo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = generate_background_image((0,80,0), (0,0,80), size=(256,256))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test overlay\n",
    "img_new = img.copy()\n",
    "img_new.paste(logo, (50,50), logo)\n",
    "img_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_new = img.copy()\n",
    "logo_tfs = torchvision.transforms.Grayscale()(logo)\n",
    "\n",
    "img_new.paste(logo_tfs, (50,50), logo)\n",
    "img_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_new = img.copy()\n",
    "logo_tfs = torchvision.transforms.RandomAffine(45, translate=(0.1,0.1), scale=(1,1), shear=10)(logo)\n",
    "\n",
    "img_new.paste(logo_tfs, (50,50), logo_tfs)\n",
    "img_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_augmented_image(size=(512,512),\n",
    "                             logo_file='CLOUDERALOGO.jpg',\n",
    "                             N_tfms_to_apply=2,\n",
    "                             low_frac=0.30,\n",
    "                             high_frac=0.90):\n",
    "        \n",
    "    logo = Image.open(logo_file) #inefficient to open N times but okay for now\n",
    "\n",
    "    #logo\n",
    "    #step 1: get resize parameters\n",
    "    #low_frac = 0.30\n",
    "    #high_frac = 0.90\n",
    "    frac0 = (np.random.random()*(high_frac-low_frac) + low_frac)\n",
    "    frac1 = (np.random.random()*(high_frac-low_frac) + low_frac)\n",
    "    logo_size = (int(frac0*size[0]), int(frac1*size[1]))\n",
    "\n",
    "    #logo_size = (128,128) #introduce some randomness\n",
    "\n",
    "    #step 2: get mask and apply resizing\n",
    "    logo = make_logo_transparent(logo)\n",
    "    logo = logo.resize(logo_size)\n",
    "\n",
    "    #step 3: apply transformations\n",
    "    tfms_list = [                \n",
    "                    transforms.RandomRotation(45, expand=False, fill=255),\n",
    "                    transforms.RandomAffine(0, translate=(0.3,0.3)), #also include truncations\n",
    "                    transforms.RandomAffine(0, shear=(30,30))\n",
    "                ]\n",
    "\n",
    "    N_tfms = len(tfms_list)\n",
    "\n",
    "    logo_tfms = logo.copy()\n",
    "    for i in range(N_tfms_to_apply): #apply N transformations\n",
    "        logo_tfms = tfms_list[np.random.randint(N_tfms)](logo_tfms)\n",
    "        #logo_tfms = make_logo_transparent(logo_tfms)\n",
    "\n",
    "    logo_tfms = make_logo_transparent(logo_tfms)\n",
    "\n",
    "    #step 4: background image \n",
    "    colors = [(255,0,0), (0,255,0), (0,0,255), (128,0,0), (0,128,0), (0,0,128), \n",
    "              (0,0,0), (255,255,255), (128,128,128),        \n",
    "              (255,255,0), (255,0,255), (0,255,255), (128,128,0), (128,0,128), (0,128,128)]\n",
    "    N_colors = len(colors)\n",
    "\n",
    "    colors_picked = np.array(colors)[np.random.randint(0, N_colors, size=2)]\n",
    "\n",
    "    bkg = generate_background_image(colors_picked[0], colors_picked[1], size=size)\n",
    "\n",
    "    #step 5: superimpose at random locations\n",
    "\n",
    "    location_x = [0, bkg.size[0]-logo.size[0]]\n",
    "    location_y = [0, bkg.size[1]-logo.size[1]]\n",
    "\n",
    "    loc = (np.random.randint(*location_x), np.random.randint(*location_y))\n",
    "\n",
    "    bkg.paste(logo_tfms, loc, logo_tfms)\n",
    "    \n",
    "    return bkg, (*size, *loc, loc[0] + logo_size[0], loc[1] + logo_size[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_bbox(img, bbox):\n",
    "    img_copy = img.copy()\n",
    "    draw = ImageDraw.Draw(img_copy)\n",
    "    \n",
    "    draw.rectangle([(bbox[2],bbox[3]), (bbox[4],bbox[5])], outline=128)\n",
    "    \n",
    "    return img_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_string(N=6):\n",
    "    return ''.join([chr(i) for i in np.random.randint(97,122,size=N)])\n",
    "\n",
    "def generate_augmented_dataset(N_images,\n",
    "                               size=(512,512),\n",
    "                               low_frac=0.30,\n",
    "                               high_frac=0.90,\n",
    "                               logo_file='CLOUDERALOGO.jpg',\n",
    "                               N_tfms_to_apply=2,\n",
    "                               seed=None,\n",
    "                               save_loc=None,\n",
    "                               logo_name=None):\n",
    "    \n",
    "    if seed is not None: #should really figure out all torch seeds\n",
    "        np.random.seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)    \n",
    "    else:\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "    \n",
    "    img_list, bbox_list = [], []\n",
    "    for i in range(N_images):\n",
    "        img, bbox = generate_augmented_image(size, \n",
    "                                             logo_file, \n",
    "                                             N_tfms_to_apply,\n",
    "                                             low_frac=low_frac,\n",
    "                                             high_frac=high_frac)\n",
    "        img_list.append(img)\n",
    "        bbox_list.append(bbox)\n",
    "        \n",
    "    if save_loc is not None:\n",
    "        if not os.path.exists(save_loc):\n",
    "            pathlib.Path(save_loc).mkdir(parents=True, exist_ok=True)\n",
    "        if logo_name is None:\n",
    "            raise ValueError(\"Please enter logo_name if saving images\")\n",
    "                \n",
    "        csv_fields = {'filename': [],\n",
    "                      'width': [],\n",
    "                      'height': [],\n",
    "                      'class': [],\n",
    "                      'xmin': [],\n",
    "                      'ymin': [],\n",
    "                      'xmax': [],\n",
    "                      'ymax': []}\n",
    "                \n",
    "        for img, bbox in zip(img_list, bbox_list):\n",
    "            img_name = f'{logo_name}_{generate_random_string()}.png'\n",
    "            img.save(os.path.join(save_loc, img_name))\n",
    "            \n",
    "            csv_fields['filename'].append(img_name)\n",
    "            csv_fields['width'].append(bbox[0])\n",
    "            csv_fields['height'].append(bbox[1])\n",
    "            csv_fields['class'].append(logo_name)\n",
    "            csv_fields['xmin'].append(bbox[2])\n",
    "            csv_fields['ymin'].append(bbox[3])\n",
    "            csv_fields['xmax'].append(bbox[4])\n",
    "            csv_fields['ymax'].append(bbox[5])\n",
    "            \n",
    "        pd.DataFrame(csv_fields).to_csv(os.path.join(save_loc, f'{logo_name}.csv'), index=False)\n",
    "    else:\n",
    "        csv_fields = None\n",
    "        \n",
    "    return img_list, bbox_list, csv_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list, bbox_list, csv_fields = generate_augmented_dataset(128, \n",
    "                                                             low_frac=0.20,\n",
    "                                                             high_frac=0.40,\n",
    "                                                             logo_file='RHLOGO.jpg',\n",
    "                                                             save_loc='rhlogo/train',\n",
    "                                                             logo_name='rhlogo')\n",
    "img_list, bbox_list, csv_fields = generate_augmented_dataset(128, \n",
    "                                                             low_frac=0.20,\n",
    "                                                             high_frac=0.40,\n",
    "                                                             logo_file='RHLOGO.jpg',\n",
    "                                                             save_loc='rhlogo/test',\n",
    "                                                             logo_name='rhlogo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert csv to json\n",
    "!python convert_csv_to_detectron.py rhlogo/train/rhlogo.csv rhlogo/train/data.json\n",
    "!python convert_csv_to_detectron.py rhlogo/test/rhlogo.csv rhlogo/test/data.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dicts(IMG_DIR):\n",
    "    '''Returns a list of dicts - one for each image\n",
    "    Each dict contains labels and bounding boxes\n",
    "    \n",
    "    Each folder (train, val, test) contains a data.json file\n",
    "    '''\n",
    "\n",
    "    path = os.path.join(IMG_DIR, 'data.json')\n",
    "    dataset_dict = json.load(open(path))\n",
    "\n",
    "    return dataset_dict\n",
    "\n",
    "def register(IMG_DIR, class_names, subfolders=['train', 'test']):\n",
    "    '''Register datasets for detectron2\n",
    "    '''\n",
    "\n",
    "    for d in subfolders:\n",
    "        DatasetCatalog.register(f\"{IMG_DIR}_{d}\", lambda d=d: get_dicts(f'{IMG_DIR}/{d}'))\n",
    "        MetadataCatalog.get(f\"{IMG_DIR}_{d}\").set(thing_classes=class_names)\n",
    "\n",
    "def get_metadata(dataset_name):\n",
    "    metadata = MetadataCatalog.get(dataset_name)\n",
    "\n",
    "    return metadata        \n",
    "\n",
    "def sample_plot(dataset_dict, metadata, LOC):\n",
    "    #LOC = 'logos3/train'\n",
    "\n",
    "    d = random.sample(dataset_dict, 1)[0]\n",
    "    print(d)\n",
    "    img = cv2.imread(os.path.join(LOC, d[\"file_name\"]))\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    plt.imshow(vis.get_image()[:, :, ::-1])\n",
    "    \n",
    "def prepare_for_training(N_iter,\n",
    "                         output_dir,\n",
    "                         train_dataset_name,\n",
    "                         N_classes,\n",
    "                         start_training=False):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_C4_1x.yaml\"))\n",
    "    cfg.OUTPUT_DIR = output_dir\n",
    "    cfg.DATASETS.TRAIN = (train_dataset_name,)\n",
    "    cfg.DATASETS.TEST = ()\n",
    "    cfg.DATALOADER.NUM_WORKERS = 2\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_C4_1x.yaml\")  # Let training initialize from model zoo\n",
    "    cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "    cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "    cfg.SOLVER.MAX_ITER = N_iter    # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = N_classes  # 4 classes\n",
    "\n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "    trainer = DefaultTrainer(cfg)\n",
    "    trainer.resume_or_load(resume=False)\n",
    "\n",
    "    if start_training:\n",
    "        trainer.train()\n",
    "\n",
    "    return trainer, cfg    \n",
    "\n",
    "def prepare_for_inference(cfg, test_dataset_name, threshold=0.70):\n",
    "    print(f\"Reading weights from output dir: {cfg.OUTPUT_DIR}\")\n",
    "    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = threshold   # set the testing threshold for this model\n",
    "    cfg.DATASETS.TEST = (test_dataset_name, )\n",
    "    predictor = DefaultPredictor(cfg)    \n",
    "\n",
    "    return predictor\n",
    "\n",
    "def infer_img(predictor, img_filename, metadata):\n",
    "    img = cv2.imread(img_filename)\n",
    "    outputs = predictor(img)\n",
    "\n",
    "    v = Visualizer(img[:,:,::-1], metadata=metadata, scale=0.8)\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    plt.imshow(v.get_image())\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhlogo_train = get_dicts('rhlogo/train')\n",
    "register('rhlogo', ['rhlogo'], ['train', 'test'])\n",
    "rhlogo_train_metadata = get_metadata('rhlogo_train')\n",
    "sample_plot(rhlogo_train, rhlogo_train_metadata, 'rhlogo/train')\n",
    "trainer, cfg = prepare_for_training(2000, 'rhlogo_output', 'rhlogo_train', 1, start_training=True)\n",
    "\n",
    "trainer_discard, cfg = prepare_for_training(2000, 'rhlogo_output', 'rhlogo_train', 1, start_training=False)\n",
    "predictor = prepare_for_inference(cfg, 'rhlogo_test', threshold=0.20)\n",
    "\n",
    "infer_img(predictor, 'rhlogo_pvsvsf.png', rhlogo_train_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhlogo_train = get_dicts('rhlogo/train')\n",
    "register('rhlogo', ['rhlogo'], ['train', 'test'])\n",
    "rhlogo_train_metadata = get_metadata('rhlogo_train')\n",
    "sample_plot(rhlogo_train, rhlogo_train_metadata, 'rhlogo/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer, cfg = prepare_for_training(2000, 'rhlogo_output', 'rhlogo_train', 1, start_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.DEVICE = \"cpu\"\n",
    "predictor = prepare_for_inference(cfg, 'rhlogo_test', threshold=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "infer_img(predictor, 'RHBKG4.jpg', rhlogo_train_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to do:\n",
    "\n",
    "1. add mAP (and others) as a metric\n",
    "\n",
    "2. look for models with lower latency\n",
    "\n",
    "3. more diverse backgrounds\n",
    "\n",
    "4. add all 3 logos\n",
    "\n",
    "5. test onnx export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on 4 logos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
